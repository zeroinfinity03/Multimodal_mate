# Multimodal Mate

- Multimodal Mate** is an advanced web application that leverages artificial intelligence to process and understand various types of user inputs, including text, images, and documents.
- It combines the capabilities of the **Gemini 1.5 Flash** language model for multimodal processing with a **Retrieval-Augmented Generation (RAG)** pipeline powered by **LlamaIndex**, enhancing document-based query handling.
- This architecture provides an intuitive interface coupled with robust backend processing.

## Features

- Multimodal Input Processing**: Seamlessly handles and interprets text, images, and documents.
- Advanced Language Model**: Utilizes **Gemini 1.5 Flash** for state-of-the-art natural language understanding and generation.
- RAG Pipeline**: Employs **LlamaIndex** for efficient document indexing and retrieval, enhancing the relevance and accuracy of responses.
- Supported Document Types**: Processes PDFs, PowerPoint presentations (PPT), Excel spreadsheets (XLSX), CSV files, and JSON documents.
- Responsive User Interface**: Built with **HTML**, **Tailwind CSS**, and **JavaScript** to ensure a smooth and intuitive user experience.

## Technologies Used

- **Backend**: [FastAPI](https://fastapi.tiangolo.com/)
- **Frontend**: HTML, Tailwind CSS, JavaScript
- **AI Model**: [Gemini 1.5 Flash](https://example.com/gemini-model) *(replace with actual link if available)*
- **Document Processing**: [LlamaIndex](https://llamaindex.readthedocs.io/en/latest/), SimpleDirectoryReader
- **Embedding Model**: [sentence-transformers/all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)


## Setup and Installation



## Setup and Installation

### Clone the Repository

```bash
git clone https://github.com/yourusername/multimodal_mate.git
cd multimodal_mate
```

### Install Dependencies

```bash
pip install -r requirements.txt
```

### Environment Variables

Create a `.env` file in the root directory and add your API keys and other environment variables. Example `.env` content:

```env
GOOGLE_API_KEY=your_google_api_key_here
PERPLEXITY_API_KEY=your_perplexity_api_key_here
GOOGLE_APPLICATION_CREDENTIALS=credentials/google_cloud_credentials.json
```

### Run the Application

```bash
uvicorn main:app --reload
```

### Access the Application

Open your browser and go to [http://127.0.0.1:8000](http://127.0.0.1:8000).

## Usage

- **Visionary**: Provides real-time assistance for visually impaired users.
- **Multimodal Mate**: Handles text, image, and document-based queries.

## Troubleshooting

- **API Keys Issues**: Ensure that you have enabled the correct APIs in the Google Cloud Console.
- **Dependencies Issues**: Try updating `requirements.txt` and running `pip install -r requirements.txt` again.

## Contributing

Contributions are welcome! Please fork the repository and submit a pull request for any improvements or bug fixes.

## License

This project is licensed under the [MIT License](LICENSE).

# Multimodal Mate

**Multimodal Mate** is an advanced web application that leverages artificial intelligence to process and understand various types of user inputs, including text, images, and documents. It combines the capabilities of the **Gemini 1.5 Flash** language model for multimodal processing with a **Retrieval-Augmented Generation (RAG)** pipeline powered by **LlamaIndex**, enhancing document-based query handling. This architecture provides an intuitive interface coupled with robust backend processing.

## Features

- **Multimodal Input Processing**: Seamlessly handles and interprets text, images, and documents.
- **Advanced Language Model**: Utilizes **Gemini 1.5 Flash** for state-of-the-art natural language understanding and generation.
- **RAG Pipeline**: Employs **LlamaIndex** for efficient document indexing and retrieval, enhancing the relevance and accuracy of responses.
- **Supported Document Types**: Processes PDFs, PowerPoint presentations (PPT), Excel spreadsheets (XLSX), CSV files, and JSON documents.
- **Responsive User Interface**: Built with **HTML**, **Tailwind CSS**, and **JavaScript** to ensure a smooth and intuitive user experience.

## Technologies Used

- **Backend**: [FastAPI](https://fastapi.tiangolo.com/)
- **Frontend**: HTML, Tailwind CSS, JavaScript
- **AI Model**: [Gemini 1.5 Flash](https://example.com/gemini-model) 
- **Document Processing**: [LlamaIndex](https://llamaindex.readthedocs.io/en/latest/), SimpleDirectoryReader
- **Embedding Model**: [sentence-transformers/all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)


## Setup and Installation



## Setup and Installation

### Clone the Repository

```bash
git clone https://github.com/yourusername/multimodal_mate.git
cd multimodal_mate
```

### Install Dependencies

```bash
pip install -r requirements.txt
```

### Environment Variables

Create a `.env` file in the root directory and add your API keys and other environment variables. Example `.env` content:

```env
GOOGLE_API_KEY=your_google_api_key_here
PERPLEXITY_API_KEY=your_perplexity_api_key_here
GOOGLE_APPLICATION_CREDENTIALS=credentials/google_cloud_credentials.json
```

### Run the Application

```bash
uvicorn main:app --reload
```

### Access the Application

Open your browser and go to [http://127.0.0.1:8000](http://127.0.0.1:8000).

## Usage

- **Visionary**: Provides real-time assistance for visually impaired users.
- **Multimodal Mate**: Handles text, image, and document-based queries.

## Troubleshooting

- **API Keys Issues**: Ensure that you have enabled the correct APIs in the Google Cloud Console.
- **Dependencies Issues**: Try updating `requirements.txt` and running `pip install -r requirements.txt` again.

## Contributing

Contributions are welcome! Please fork the repository and submit a pull request for any improvements or bug fixes.

## License

This project is licensed under the [MIT License](LICENSE).


### **Explanation:**








```markdown
# Multimodal Mate

**Multimodal Mate** is an advanced web application that leverages artificial intelligence to process and understand various types of user inputs, including text, images, and documents. It integrates the **Gemini 1.5 Flash** language model for multimodal processing with a **Retrieval-Augmented Generation (RAG)** pipeline powered by **LlamaIndex**, enhancing document-based query handling. This architecture offers an intuitive interface coupled with robust backend processing capabilities.

## Features

- **Multimodal Input Processing**: Seamlessly handles and interprets text, images, and documents.
- **Advanced Language Model**: Utilizes **Gemini 1.5 Flash** for state-of-the-art natural language understanding and generation.
- **RAG Pipeline**: Employs **LlamaIndex** for efficient document indexing and retrieval, enhancing the relevance and accuracy of responses.
- **Supported Document Types**: Processes PDFs, PowerPoint presentations (PPT), Excel spreadsheets (XLSX), CSV files, and JSON documents.
- **Responsive User Interface**: Built with **HTML**, **Tailwind CSS**, and **JavaScript** to ensure a smooth and intuitive user experience.

## Technologies Used

- **Backend**: [FastAPI](https://fastapi.tiangolo.com/)
- **Frontend**: HTML, Tailwind CSS, JavaScript
- **AI Model**: [Gemini 1.5 Flash](https://example.com/gemini-model) *(replace with actual link if available)*
- **Document Processing**: [LlamaIndex](https://llamaindex.readthedocs.io/en/latest/), SimpleDirectoryReader
- **Embedding Model**: [sentence-transformers/all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)

## Setup and Installation

### 1. Clone the Repository

```bash
git clone https://github.com/yourusername/multimodal_mate.git
cd multimodal_mate
```

### 2. Install Dependencies

Ensure you have Python 3.8 or higher installed. Then, install the required packages:

```bash
pip install -r requirements.txt
```

### 3. Configure Environment Variables

Create a `.env` file in the root directory and add your necessary API keys and configurations. Example `.env` content:

```env
GOOGLE_API_KEY=your_google_api_key_here
PERPLEXITY_API_KEY=your_perplexity_api_key_here
GOOGLE_APPLICATION_CREDENTIALS=credentials/google_cloud_credentials.json
```

### 4. Run the Application

Start the FastAPI server using Uvicorn:

```bash
uvicorn main:app --reload
```

### 5. Access the Application

Open your web browser and navigate to [http://127.0.0.1:8000](http://127.0.0.1:8000) to access Multimodal Mate.

## Usage

- **Multimodal Queries**: Submit queries containing text, images, or a combination to receive intelligent, context-aware responses.
- **Document-Based Queries**: Upload documents in supported formats (PDF, PPT, XLSX, CSV, JSON) and query specific content within these documents.
- **Real-Time Assistance**: Utilize real-time features tailored for visually impaired users, including voice processing and navigation services.

## Troubleshooting

- **API Keys Issues**: Ensure that you have enabled the necessary APIs in the Google Cloud Console and that your API keys are correctly set in the `.env` file.
- **Dependency Issues**: If you encounter problems with dependencies, try updating the `requirements.txt` file and reinstalling the packages:

  ```bash
  pip install --upgrade -r requirements.txt
  ```

## Contributing

Contributions are welcome! Please follow these steps to contribute:

1. Fork the repository.
2. Create a new branch for your feature or bugfix.
3. Commit your changes with clear messages.
4. Submit a pull request detailing your changes and their impact.

## License

This project is licensed under the [MIT License](LICENSE).


